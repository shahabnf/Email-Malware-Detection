#!/usr/bin/env python
# coding: utf-8

import numpy as np
import random
import re
from nltk.util import ngrams
import itertools
import pandas as pd
from sklearn import svm
from joblib import dump, load
from sklearn.linear_model import SGDClassifier
from sklearn.model_selection import train_test_split
import csv


#variable
# test_size_var = float(input("Enter Test Size: "))
# no_of_rows_var =  int(input("Enter Row number: "))

alphanum = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z','0','1','2','3','4','5','6','7','8','9']
permutations = itertools.product(alphanum, repeat=3)
featuresDict = {}
counter = 0
for perm in permutations:
    #print(perm)
    f=''
    for char in perm:
        f = f+char;
    featuresDict[(''.join(perm))] = counter
    counter = counter + 1


def generate_ngram(sentence):
    s = sentence.lower()
    s = ''.join(e for e in s if e.isalnum()) #replace spaces and slashes
    processedList = []
    for tup in list(ngrams(s,3)):
        processedList.append((''.join(tup)))
    return processedList


def preprocess_sentences(dataframe, X, y):
    # print(dataframe)
    for index,row in df.iterrows():
        url = row['url'].strip().replace("https://","")
        url = row['url'].strip().replace("http://","")
        url = url.replace("http://","")
        url = re.sub(r'\.[A-Za-z0-9]+/*','',url)
        for gram in generate_ngram(url):
            try:
                X[index][featuresDict[gram]] = X[index][featuresDict[gram]] + 1
            except:
                print(gram,"doesn't exist")
        y[index] = int(row['label'])
    return (X,y)



# Test Accuracy by chaning variables
# uncomment the following if you want to receive inputs from command line
# test_size_var = float(input("Enter Test Size: "))
# no_of_rows_var =  int(input("Enter Row number: "))

test_size_list = [0.04,0.05,0.06,0.07,0.08,0.09,0.1,0.11,0.12,0.13,0.14,0.15,0.16,0.17,0.18,0.19,0.20,0.21,0.22,0.23,0.24,0.25,0.26,0.27,0.28,0.29,0.30]
no_of_rows_list = [650,700,750]

for test_size_var in test_size_list:
   for no_of_rows_var in no_of_rows_list:

# for test_size_var, no_of_rows_var in vaiable_list:

    malData = pd.read_csv("Dataset\\feature-updated-dataset.csv")
    # train_df, test_df = train_test_split(malData, test_size=0.18)
    train_df, test_df = train_test_split(malData, test_size=test_size_var)
    # malData.tail()

    # no_of_rows = 7000
    no_of_rows = no_of_rows_var
    no_of_batches = int(train_df.shape[0]/no_of_rows) +1
    classifier = SGDClassifier()
    #print(no_of_batches)
    for i in range(0, no_of_batches):
        start = no_of_rows*i
        if start + no_of_rows > train_df.shape[0] :
            df = train_df.iloc[start:,:]
        else :
            df = train_df.iloc[start:start+no_of_rows, :]
        df = df.reset_index()
        (X,y) = preprocess_sentences(df, \
                                    np.zeros([df.shape[0], 46656],dtype="int"), \
                                    np.zeros(df.shape[0],dtype="int"))
        classifier.partial_fit(X, y, classes=np.unique(y))


    # no_of_rows = 7000
    no_of_rows = no_of_rows_var
    no_of_batches = int(test_df.shape[0]/no_of_rows) +1
    #print(no_of_batches)
    correct = 0;
    incorrect = 0
    for i in range(0, no_of_batches):
        start = no_of_rows*i
        if start + no_of_rows > train_df.shape[0] :
            df = train_df.iloc[start:,:]
        else :
            df = test_df.iloc[start:start+no_of_rows, :]
        df = df.reset_index()
        (X_test,y_test) = preprocess_sentences(df, \
                                    np.zeros([df.shape[0], 46656],dtype="int"), \
                                    np.zeros(df.shape[0],dtype="int"))
        y_pred = classifier.predict(X_test)
        for index,row in df.iterrows():
            if row['label'] == y_pred[index]:
                correct = correct+1
            else:
                incorrect = incorrect + 1  


    print("Correct Predictions ", correct)
    print("Incorrect Predictions ", incorrect)
    accuracy = (correct/test_df.shape[0])*100
    print("Accuracy of the model is: "'{0:.4g}'.format(accuracy), '%')


    with open('ModelAccuracyResult.csv', 'a', newline='') as csvfile:
        # fieldnames = ['first_name', 'last_name']
        fieldnames = ['test_size_var', 'no_of_rows_var', 'Correct Predictions', 'Incorrect Predictions', 'accuracy']
        # writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

        writer.writeheader()
        writer.writerow({'test_size_var': test_size_var, \
                         'no_of_rows_var': no_of_rows_var, 'Correct Predictions': correct, \
                            'Incorrect Predictions': incorrect,  'accuracy': accuracy \
                                })
        
    